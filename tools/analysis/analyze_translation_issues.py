#!/usr/bin/env python3
"""
ç¿»è¨³å•é¡Œã®åˆ†æã¨å„ªå…ˆé †ä½ä»˜ã‘ãƒ„ãƒ¼ãƒ«

ãƒ“ãƒ«ãƒ‰è­¦å‘Šã‚’åˆ†æã—ã€æ—¥æœ¬èªç¿»è¨³ãŒåæ˜ ã•ã‚Œãªã„åŸå› ã‚’ç‰¹å®šã—ã¾ã™ã€‚
- RSTæ§‹æ–‡ã‚¨ãƒ©ãƒ¼
- Sphinxè­¦å‘Š
- æœªç¿»è¨³ç®‡æ‰€
- æ§‹æ–‡ãƒŸã‚¹ã§åæ˜ ã•ã‚Œã¦ã„ãªã„ç¿»è¨³

ä½¿ã„æ–¹:
    # ãƒ“ãƒ«ãƒ‰ã—ã¦è­¦å‘Šã‚’åˆ†æ
    cd docs && make clean && make html-ja 2>&1 | tee build.log
    python tools/analysis/analyze_translation_issues.py build.log

    # HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    python tools/analysis/analyze_translation_issues.py build.log --html-report report.html
    
    # å„ªå…ˆåº¦é †ã«å•é¡Œã‚’ã‚½ãƒ¼ãƒˆ
    python tools/analysis/analyze_translation_issues.py build.log --sort-by priority
"""

import re
import sys
import json
import argparse
from pathlib import Path
from collections import defaultdict, Counter
from typing import Dict, List, Tuple
import subprocess

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
SCRIPT_DIR = Path(__file__).parent
PROJECT_ROOT = SCRIPT_DIR.parent.parent
DOCS_ROOT = PROJECT_ROOT / "docs"


class TranslationIssueAnalyzer:
    """ç¿»è¨³å•é¡Œã®åˆ†æå™¨"""
    
    def __init__(self, build_log_path: Path):
        self.build_log_path = build_log_path
        self.warnings = []
        self.stats = Counter()
        self.issues_by_file = defaultdict(list)
        self.issues_by_type = defaultdict(list)
        
        # è­¦å‘Šã‚¿ã‚¤ãƒ—ã®é‡å¤§åº¦ãƒãƒƒãƒ”ãƒ³ã‚°
        self.severity_map = {
            # é«˜å„ªå…ˆåº¦ï¼ˆæ—¥æœ¬èªãŒè¡¨ç¤ºã•ã‚Œãªã„åŸå› ï¼‰
            'undefined label': 'critical',
            'unknown document': 'critical',
            'inconsistent term references': 'high',
            'inconsistent references': 'high',
            
            # ä¸­å„ªå…ˆåº¦ï¼ˆè¡¨ç¤ºã«å½±éŸ¿ã™ã‚‹ãŒè‡´å‘½çš„ã§ã¯ãªã„ï¼‰
            'Inline interpreted text or phrase reference start-string without end-string': 'medium',
            'Inline emphasis start-string without end-string': 'medium',
            'Inline literal start-string without end-string': 'medium',
            'Inline strong start-string without end-string': 'medium',
            
            # ä½å„ªå…ˆåº¦ï¼ˆè¡¨ç¤ºã«å¤§ããªå½±éŸ¿ãªã—ï¼‰
            'Block quote ends without a blank line': 'low',
            'Title underline too short': 'low',
            'Mismatch': 'low',
        }
    
    def parse_build_log(self):
        """ãƒ“ãƒ«ãƒ‰ãƒ­ã‚°ã‚’ãƒ‘ãƒ¼ã‚¹"""
        print(f"[INFO] ãƒ“ãƒ«ãƒ‰ãƒ­ã‚°ã‚’èª­ã¿è¾¼ã¿ä¸­: {self.build_log_path}")
        
        if not self.build_log_path.exists():
            print(f"âŒ ãƒ“ãƒ«ãƒ‰ãƒ­ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.build_log_path}")
            return
        
        with open(self.build_log_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
        
        # è­¦å‘Šã‚’æŠ½å‡º
        warning_pattern = r'(.+?):(\d+):\s*WARNING:\s*(.+?)(?:\n|$)'
        matches = re.finditer(warning_pattern, content, re.MULTILINE)
        
        for match in matches:
            file_path = match.group(1)
            line_num = int(match.group(2))
            message = match.group(3).strip()
            
            # è­¦å‘Šã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š
            warning_type = self.classify_warning(message)
            severity = self.get_severity(warning_type)
            
            warning = {
                'file': file_path,
                'line': line_num,
                'message': message,
                'type': warning_type,
                'severity': severity,
            }
            
            self.warnings.append(warning)
            self.stats[warning_type] += 1
            self.issues_by_file[file_path].append(warning)
            self.issues_by_type[warning_type].append(warning)
        
        print(f"[INFO] è­¦å‘Šæ•°: {len(self.warnings)}")
        print()
    
    def classify_warning(self, message: str) -> str:
        """è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ã‚¿ã‚¤ãƒ—ã‚’åˆ†é¡"""
        # å„ã‚¿ã‚¤ãƒ—ã‚’ãƒã‚§ãƒƒã‚¯
        if 'undefined label' in message.lower():
            return 'undefined label'
        elif 'unknown document' in message.lower():
            return 'unknown document'
        elif 'inconsistent term references' in message.lower():
            return 'inconsistent term references'
        elif 'inconsistent references' in message.lower():
            return 'inconsistent references'
        elif 'Inline interpreted text' in message:
            return 'Inline interpreted text or phrase reference start-string without end-string'
        elif 'Inline emphasis' in message:
            return 'Inline emphasis start-string without end-string'
        elif 'Inline literal' in message:
            return 'Inline literal start-string without end-string'
        elif 'Inline strong' in message:
            return 'Inline strong start-string without end-string'
        elif 'Block quote ends' in message:
            return 'Block quote ends without a blank line'
        elif 'Title underline' in message:
            return 'Title underline too short'
        elif 'Mismatch' in message:
            return 'Mismatch'
        elif 'term not in glossary' in message:
            return 'term not in glossary'
        elif 'duplicate term' in message:
            return 'duplicate term description'
        elif "isn't included in any toctree" in message:
            return 'document not in toctree'
        else:
            return 'other'
    
    def get_severity(self, warning_type: str) -> str:
        """è­¦å‘Šã‚¿ã‚¤ãƒ—ã‹ã‚‰é‡å¤§åº¦ã‚’å–å¾—"""
        return self.severity_map.get(warning_type, 'low')
    
    def analyze_japanese_label_issues(self):
        """æ—¥æœ¬èªãƒ©ãƒ™ãƒ«å‚ç…§ã®å•é¡Œã‚’åˆ†æ"""
        japanese_label_issues = []
        
        for warning in self.warnings:
            if warning['type'] == 'undefined label':
                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰æ—¥æœ¬èªãŒå«ã¾ã‚Œã‚‹ã‹ç¢ºèª
                message = warning['message']
                has_japanese = any('\u3040' <= c <= '\u309F' or
                                 '\u30A0' <= c <= '\u30FF' or
                                 '\u4E00' <= c <= '\u9FFF'
                                 for c in message)
                
                if has_japanese:
                    japanese_label_issues.append(warning)
        
        return japanese_label_issues
    
    def analyze_japanese_doc_path_issues(self):
        """æ—¥æœ¬èªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ‘ã‚¹ã®å•é¡Œã‚’åˆ†æ"""
        japanese_doc_issues = []
        
        for warning in self.warnings:
            if warning['type'] == 'unknown document':
                message = warning['message']
                has_japanese = any('\u3040' <= c <= '\u309F' or
                                 '\u30A0' <= c <= '\u30FF' or
                                 '\u4E00' <= c <= '\u9FFF'
                                 for c in message)
                
                if has_japanese:
                    japanese_doc_issues.append(warning)
        
        return japanese_doc_issues
    
    def generate_priority_report(self):
        """å„ªå…ˆé †ä½ä»˜ããƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        print("=" * 80)
        print("ğŸ“Š ç¿»è¨³å•é¡Œåˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        print("=" * 80)
        print()
        
        # çµ±è¨ˆæƒ…å ±
        print("ã€çµ±è¨ˆã€‘")
        print(f"  ç·è­¦å‘Šæ•°: {len(self.warnings)}")
        print(f"  å½±éŸ¿ã‚’å—ã‘ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(self.issues_by_file)}")
        print()
        
        # é‡å¤§åº¦åˆ¥
        severity_counts = Counter()
        for warning in self.warnings:
            severity_counts[warning['severity']] += 1
        
        print("ã€é‡å¤§åº¦åˆ¥ã€‘")
        for severity in ['critical', 'high', 'medium', 'low']:
            count = severity_counts[severity]
            if count > 0:
                icon = {'critical': 'ğŸ”´', 'high': 'ğŸŸ ', 'medium': 'ğŸŸ¡', 'low': 'âšª'}[severity]
                print(f"  {icon} {severity.upper()}: {count}ä»¶")
        print()
        
        # è­¦å‘Šã‚¿ã‚¤ãƒ—åˆ¥ï¼ˆä¸Šä½10ä»¶ï¼‰
        print("ã€è­¦å‘Šã‚¿ã‚¤ãƒ—åˆ¥ï¼ˆä¸Šä½10ä»¶ï¼‰ã€‘")
        for warning_type, count in self.stats.most_common(10):
            severity = self.get_severity(warning_type)
            icon = {'critical': 'ğŸ”´', 'high': 'ğŸŸ ', 'medium': 'ğŸŸ¡', 'low': 'âšª'}[severity]
            print(f"  {icon} {warning_type}: {count}ä»¶")
        print()
        
        # æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ã®å•é¡Œ
        ja_label_issues = self.analyze_japanese_label_issues()
        if ja_label_issues:
            print(f"ã€ğŸ”´ æœ€é‡è¦ã€‘æ—¥æœ¬èªãƒ©ãƒ™ãƒ«å‚ç…§ã®å•é¡Œ: {len(ja_label_issues)}ä»¶")
            print("  ã“ã‚Œã‚‰ã¯ç¿»è¨³ãŒåæ˜ ã•ã‚Œãªã„ç›´æ¥çš„ãªåŸå› ã§ã™ã€‚")
            print("  ãƒ©ãƒ™ãƒ«åã‚’è‹±èªã®ã¾ã¾ä¿æŒã—ã€è¡¨ç¤ºãƒ†ã‚­ã‚¹ãƒˆã®ã¿ç¿»è¨³ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
            print()
            for issue in ja_label_issues[:5]:
                print(f"  - {Path(issue['file']).name}:{issue['line']}")
                print(f"    {issue['message'][:80]}...")
            if len(ja_label_issues) > 5:
                print(f"  ... ä»–{len(ja_label_issues) - 5}ä»¶")
            print()
        
        # æ—¥æœ¬èªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ‘ã‚¹ã®å•é¡Œ
        ja_doc_issues = self.analyze_japanese_doc_path_issues()
        if ja_doc_issues:
            print(f"ã€ğŸ”´ æœ€é‡è¦ã€‘æ—¥æœ¬èªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ‘ã‚¹ã®å•é¡Œ: {len(ja_doc_issues)}ä»¶")
            print("  ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‚ç…§ãƒ‘ã‚¹ã‚’è‹±èªã®ã¾ã¾ä¿æŒã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
            print()
            for issue in ja_doc_issues[:5]:
                print(f"  - {Path(issue['file']).name}:{issue['line']}")
                print(f"    {issue['message'][:80]}...")
            if len(ja_doc_issues) > 5:
                print(f"  ... ä»–{len(ja_doc_issues) - 5}ä»¶")
            print()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ã®å•é¡Œï¼ˆä¸Šä½10ä»¶ï¼‰
        print("ã€å½±éŸ¿ã‚’å—ã‘ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå•é¡ŒãŒå¤šã„é †ã€ä¸Šä½10ä»¶ï¼‰ã€‘")
        sorted_files = sorted(self.issues_by_file.items(), 
                            key=lambda x: len(x[1]), reverse=True)
        
        for file_path, issues in sorted_files[:10]:
            file_name = Path(file_path).name
            critical_count = sum(1 for i in issues if i['severity'] == 'critical')
            high_count = sum(1 for i in issues if i['severity'] == 'high')
            
            severity_str = ""
            if critical_count > 0:
                severity_str += f"ğŸ”´{critical_count} "
            if high_count > 0:
                severity_str += f"ğŸŸ {high_count}"
            
            print(f"  {file_name}: {len(issues)}ä»¶ {severity_str}")
        print()
    
    def generate_html_report(self, output_path: Path):
        """HTMLå½¢å¼ã®è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        # é‡å¤§åº¦åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ
        severity_counts = Counter()
        for warning in self.warnings:
            severity_counts[warning['severity']] += 1
        
        # æ—¥æœ¬èªé–¢é€£ã®å•é¡Œ
        ja_label_issues = self.analyze_japanese_label_issues()
        ja_doc_issues = self.analyze_japanese_doc_path_issues()
        
        html_content = f"""<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¿»è¨³å•é¡Œåˆ†æãƒ¬ãƒãƒ¼ãƒˆ</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }}
        h1 {{
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
        }}
        h2 {{
            color: #2c3e50;
            margin-top: 30px;
            border-bottom: 2px solid #bdc3c7;
            padding-bottom: 5px;
        }}
        .stats {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }}
        .stat-card {{
            background: white;
            padding: 15px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        .stat-card h3 {{
            margin: 0 0 10px 0;
            color: #7f8c8d;
            font-size: 14px;
        }}
        .stat-card .value {{
            font-size: 28px;
            font-weight: bold;
        }}
        .critical {{ color: #e74c3c; }}
        .high {{ color: #e67e22; }}
        .medium {{ color: #f39c12; }}
        .low {{ color: #95a5a6; }}
        
        .issue-card {{
            background: white;
            padding: 15px;
            margin: 10px 0;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        .issue-card.critical {{ border-left: 4px solid #e74c3c; }}
        .issue-card.high {{ border-left: 4px solid #e67e22; }}
        .issue-card.medium {{ border-left: 4px solid #f39c12; }}
        .issue-card.low {{ border-left: 4px solid #95a5a6; }}
        
        .issue-header {{
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
        }}
        .issue-file {{
            font-weight: bold;
            color: #2c3e50;
        }}
        .issue-line {{
            background: #ecf0f1;
            padding: 2px 8px;
            border-radius: 4px;
            font-size: 12px;
        }}
        .issue-message {{
            font-family: monospace;
            background: #f8f9fa;
            padding: 10px;
            border-radius: 4px;
            margin-top: 10px;
            font-size: 13px;
            line-height: 1.4;
        }}
        .badge {{
            display: inline-block;
            padding: 3px 8px;
            border-radius: 4px;
            font-size: 11px;
            font-weight: bold;
            text-transform: uppercase;
        }}
        .badge.critical {{ background: #e74c3c; color: white; }}
        .badge.high {{ background: #e67e22; color: white; }}
        .badge.medium {{ background: #f39c12; color: white; }}
        .badge.low {{ background: #95a5a6; color: white; }}
        
        .warning-type-list {{
            list-style: none;
            padding: 0;
        }}
        .warning-type-list li {{
            padding: 8px;
            margin: 5px 0;
            background: white;
            border-radius: 4px;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }}
        .count {{
            background: #3498db;
            color: white;
            padding: 2px 10px;
            border-radius: 12px;
            font-weight: bold;
        }}
        
        .alert {{
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }}
        .alert.critical {{
            background: #fadbd8;
            border-left: 4px solid #e74c3c;
        }}
        .alert h3 {{
            margin: 0 0 10px 0;
            color: #c0392b;
        }}
        
        table {{
            width: 100%;
            border-collapse: collapse;
            background: white;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        th, td {{
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #ecf0f1;
        }}
        th {{
            background: #34495e;
            color: white;
            font-weight: bold;
        }}
        tr:hover {{
            background: #f8f9fa;
        }}
    </style>
</head>
<body>
    <h1>ğŸ“Š ç¿»è¨³å•é¡Œåˆ†æãƒ¬ãƒãƒ¼ãƒˆ</h1>
    <p>ãƒ“ãƒ«ãƒ‰ãƒ­ã‚°: <code>{self.build_log_path.name}</code></p>
    
    <div class="stats">
        <div class="stat-card">
            <h3>ç·è­¦å‘Šæ•°</h3>
            <div class="value">{len(self.warnings)}</div>
        </div>
        <div class="stat-card">
            <h3>å½±éŸ¿ãƒ•ã‚¡ã‚¤ãƒ«æ•°</h3>
            <div class="value">{len(self.issues_by_file)}</div>
        </div>
        <div class="stat-card">
            <h3>Critical</h3>
            <div class="value critical">{severity_counts['critical']}</div>
        </div>
        <div class="stat-card">
            <h3>High</h3>
            <div class="value high">{severity_counts['high']}</div>
        </div>
        <div class="stat-card">
            <h3>Medium</h3>
            <div class="value medium">{severity_counts['medium']}</div>
        </div>
        <div class="stat-card">
            <h3>Low</h3>
            <div class="value low">{severity_counts['low']}</div>
        </div>
    </div>
"""
        
        # æ—¥æœ¬èªé–¢é€£ã®å•é¡Œã‚’è¡¨ç¤º
        if ja_label_issues or ja_doc_issues:
            html_content += """
    <h2>ğŸ”´ æœ€é‡è¦: æ—¥æœ¬èªé–¢é€£ã®å•é¡Œ</h2>
    <div class="alert critical">
        <h3>âš ï¸ ã“ã‚Œã‚‰ã¯ç¿»è¨³ãŒåæ˜ ã•ã‚Œãªã„ç›´æ¥çš„ãªåŸå› ã§ã™</h3>
        <p>ãƒ©ãƒ™ãƒ«åã‚„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ‘ã‚¹ã‚’è‹±èªã®ã¾ã¾ä¿æŒã—ã€è¡¨ç¤ºãƒ†ã‚­ã‚¹ãƒˆã®ã¿ç¿»è¨³ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚</p>
    </div>
"""
            
            if ja_label_issues:
                html_content += f"""
    <h3>æ—¥æœ¬èªãƒ©ãƒ™ãƒ«å‚ç…§ã®å•é¡Œ ({len(ja_label_issues)}ä»¶)</h3>
"""
                for issue in ja_label_issues[:20]:
                    file_name = Path(issue['file']).name
                    html_content += f"""
    <div class="issue-card critical">
        <div class="issue-header">
            <span class="issue-file">{file_name}</span>
            <span class="issue-line">è¡Œ {issue['line']}</span>
        </div>
        <div class="issue-message">{issue['message']}</div>
    </div>
"""
            
            if ja_doc_issues:
                html_content += f"""
    <h3>æ—¥æœ¬èªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ‘ã‚¹ã®å•é¡Œ ({len(ja_doc_issues)}ä»¶)</h3>
"""
                for issue in ja_doc_issues[:20]:
                    file_name = Path(issue['file']).name
                    html_content += f"""
    <div class="issue-card critical">
        <div class="issue-header">
            <span class="issue-file">{file_name}</span>
            <span class="issue-line">è¡Œ {issue['line']}</span>
        </div>
        <div class="issue-message">{issue['message']}</div>
    </div>
"""
        
        # è­¦å‘Šã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ
        html_content += """
    <h2>è­¦å‘Šã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ</h2>
    <ul class="warning-type-list">
"""
        for warning_type, count in self.stats.most_common():
            severity = self.get_severity(warning_type)
            html_content += f"""
        <li>
            <span><span class="badge {severity}">{severity}</span> {warning_type}</span>
            <span class="count">{count}</span>
        </li>
"""
        html_content += """
    </ul>
    
    <h2>å½±éŸ¿ã‚’å—ã‘ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå•é¡ŒãŒå¤šã„é †ï¼‰</h2>
    <table>
        <thead>
            <tr>
                <th>ãƒ•ã‚¡ã‚¤ãƒ«</th>
                <th>è­¦å‘Šæ•°</th>
                <th>Critical</th>
                <th>High</th>
                <th>Medium</th>
                <th>Low</th>
            </tr>
        </thead>
        <tbody>
"""
        
        sorted_files = sorted(self.issues_by_file.items(), 
                            key=lambda x: len(x[1]), reverse=True)
        
        for file_path, issues in sorted_files[:30]:
            file_name = Path(file_path).name
            counts_by_severity = Counter(i['severity'] for i in issues)
            
            html_content += f"""
            <tr>
                <td><strong>{file_name}</strong></td>
                <td>{len(issues)}</td>
                <td class="critical">{counts_by_severity['critical']}</td>
                <td class="high">{counts_by_severity['high']}</td>
                <td class="medium">{counts_by_severity['medium']}</td>
                <td class="low">{counts_by_severity['low']}</td>
            </tr>
"""
        
        html_content += """
        </tbody>
    </table>
</body>
</html>
"""
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"âœ… HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {output_path}")
    
    def export_json(self, output_path: Path):
        """JSONå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        data = {
            'total_warnings': len(self.warnings),
            'files_affected': len(self.issues_by_file),
            'warnings': self.warnings,
            'stats': dict(self.stats),
            'japanese_label_issues': self.analyze_japanese_label_issues(),
            'japanese_doc_issues': self.analyze_japanese_doc_path_issues(),
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… JSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {output_path}")


def main():
    parser = argparse.ArgumentParser(
        description='ãƒ“ãƒ«ãƒ‰è­¦å‘Šã‚’åˆ†æã—ã¦ç¿»è¨³å•é¡Œã‚’ç‰¹å®š'
    )
    parser.add_argument('build_log', type=str,
                       help='ãƒ“ãƒ«ãƒ‰ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--html-report', type=str,
                       help='HTMLå½¢å¼ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›')
    parser.add_argument('--json', type=str,
                       help='JSONå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ')
    parser.add_argument('--sort-by', choices=['priority', 'file', 'type'],
                       default='priority',
                       help='ã‚½ãƒ¼ãƒˆé †ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: priorityï¼‰')
    
    args = parser.parse_args()
    
    build_log_path = Path(args.build_log)
    
    analyzer = TranslationIssueAnalyzer(build_log_path)
    analyzer.parse_build_log()
    analyzer.generate_priority_report()
    
    if args.html_report:
        analyzer.generate_html_report(Path(args.html_report))
    
    if args.json:
        analyzer.export_json(Path(args.json))


if __name__ == '__main__':
    main()
