#!/usr/bin/env python3
"""
HTMLãƒ“ãƒ«ãƒ‰ã®è‹±èªæ®‹å­˜éƒ¨åˆ†ã‚’æ¤œå‡ºãƒ»ä¿®æ­£ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ã„æ–¹:
  python detect_untranslated.py --check    # æ¤œå‡ºã®ã¿
  python detect_untranslated.py --fix      # æ¤œå‡ºã¨è‡ªå‹•ä¿®æ­£
  python detect_untranslated.py --report   # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
"""

import os
import sys
import json
import re
import argparse
from pathlib import Path
from bs4 import BeautifulSoup
from typing import Dict, List, Tuple, Set
import difflib

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
SCRIPT_DIR = Path(__file__).parent
PROJECT_ROOT = SCRIPT_DIR.parent.parent  # tools/analysis -> tools -> project root
DOCS_ROOT = PROJECT_ROOT / "docs"

# ãƒ“ãƒ«ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
HTML_EN = DOCS_ROOT / "build" / "html"
HTML_JA = DOCS_ROOT / "build" / "html-ja"
SOURCE_DIR = DOCS_ROOT / "source"
LOCALES_DIR = PROJECT_ROOT / "locales" / "ja" / "LC_MESSAGES"

# é™¤å¤–ã™ã¹ãè‹±èªï¼ˆæŠ€è¡“ç”¨èªã€å›ºæœ‰åè©ãªã©ï¼‰
ALLOWED_ENGLISH = {
    # æŠ€è¡“ç”¨èª
    'FIRST', 'Tech', 'Challenge', 'FTC', 'SDK', 'API', 'USB', 'WiFi', 'Bluetooth',
    'Android', 'Studio', 'OnBot', 'Java', 'Blocks', 'OpMode', 'Autonomous', 'TeleOp',
    'REV', 'Control', 'Hub', 'Driver', 'Station', 'Robot', 'Controller',
    'AprilTag', 'CAD', 'Servo', 'Motor', 'Sensor', 'IMU', 'UVC', 'PTZ',
    'Autodesk', 'PTC', 'SolidWorks', 'Fusion', 'Onshape', 'Creo',
    'GitHub', 'Git', 'Codespaces', 'VS', 'Code', 'Jupyter', 'Sphinx',
    # å›ºæœ‰åè©ãƒ»ãƒ–ãƒ©ãƒ³ãƒ‰
    'Gracious', 'Professionalism', 'Coopertition', 'STEM',
    'REV', 'Robotics', 'Education', 'Competition',
    # ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ç”¨èª
    'public', 'private', 'class', 'void', 'int', 'double', 'boolean',
    'if', 'else', 'for', 'while', 'switch', 'case', 'return',
    'import', 'package', 'extends', 'implements', 'interface',
    # å˜ä½ãƒ»è¨˜å·
    'mm', 'cm', 'kg', 'MHz', 'GHz', 'mA', 'V', 'W',
    'PDF', 'PNG', 'JPG', 'JPEG', 'GIF', 'SVG', 'MP4',
    # ãã®ä»–
    'OK', 'ID', 'URL', 'IP', 'DNS', 'HTTP', 'HTTPS',
}

# ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹HTMLã‚¯ãƒ©ã‚¹ï¼ˆã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ç­‰ï¼‰
SKIP_CLASSES = {
    'highlight', 'code', 'literal', 'download', 'reference',
    'headerlink', 'viewcode-link', 'pre', 'sig', 'guilabel'
}

# ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã‚¿ã‚°
SKIP_TAGS = {'script', 'style', 'code', 'pre', 'kbd', 'samp', 'var'}


class UntranslatedDetector:
    """æœªç¿»è¨³éƒ¨åˆ†ã®æ¤œå‡ºå™¨"""
    
    def __init__(self, verbose=False):
        self.verbose = verbose
        self.issues = []
        self.stats = {
            'files_checked': 0,
            'issues_found': 0,
            'files_with_issues': 0,
        }
    
    def log(self, message):
        """ãƒ­ã‚°å‡ºåŠ›"""
        if self.verbose:
            print(message)
    
    def is_likely_english(self, text: str) -> bool:
        """ãƒ†ã‚­ã‚¹ãƒˆãŒè‹±èªã§ã‚ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã‹ãƒã‚§ãƒƒã‚¯"""
        if not text or len(text.strip()) < 3:
            return False
        
        text = text.strip()
        
        # è¨±å¯ã•ã‚ŒãŸè‹±èªç”¨èª
        if text in ALLOWED_ENGLISH:
            return False
        
        # æ•°å­—ã®ã¿
        if text.replace('.', '').replace(',', '').replace(' ', '').isdigit():
            return False
        
        # URLã‚„ãƒ‘ã‚¹
        if re.match(r'^[\w\-./:\\]+\.(html|rst|py|java|js|css|png|jpg|pdf)$', text, re.IGNORECASE):
            return False
        
        # ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã®æ¯”ç‡ã‚’ãƒã‚§ãƒƒã‚¯
        alpha_chars = sum(1 for c in text if c.isalpha())
        ascii_alpha = sum(1 for c in text if c.isascii() and c.isalpha())
        
        if alpha_chars == 0:
            return False
        
        # 80%ä»¥ä¸ŠãŒASCIIã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆ = è‹±èªã®å¯èƒ½æ€§
        if ascii_alpha / alpha_chars > 0.8 and len(text.split()) > 1:
            return True
        
        # è‹±èªã®ä¸€èˆ¬çš„ãªå˜èªã‚’ãƒã‚§ãƒƒã‚¯
        english_words = {
            'the', 'and', 'for', 'are', 'with', 'this', 'that', 'from',
            'have', 'has', 'will', 'can', 'you', 'your', 'all', 'not',
            'but', 'our', 'out', 'what', 'which', 'when', 'where', 'how',
            'more', 'here', 'there', 'about', 'into', 'through', 'during',
        }
        
        words = re.findall(r'\b[a-z]+\b', text.lower())
        if len(words) >= 2:
            english_count = sum(1 for w in words if w in english_words)
            if english_count / len(words) > 0.3:
                return True
        
        return False
    
    def extract_text_from_element(self, element, parent_class='') -> List[Tuple[str, str]]:
        """è¦ç´ ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºï¼ˆã‚¯ãƒ©ã‚¹æƒ…å ±ä»˜ãï¼‰"""
        texts = []
        
        # NavigableStringã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if not hasattr(element, 'name') or element.name is None:
            return texts
        
        if element.name in SKIP_TAGS:
            return texts
        
        elem_classes = element.get('class', [])
        if any(cls in SKIP_CLASSES for cls in elem_classes):
            return texts
        
        if element.string and element.string.strip():
            text = element.string.strip()
            context = f"{element.name}.{'.'.join(elem_classes)}" if elem_classes else element.name
            texts.append((text, context))
        
        for child in element.children:
            if hasattr(child, 'name') and child.name:
                texts.extend(self.extract_text_from_element(child, parent_class))
        
        return texts
    
    def compare_html_files(self, en_path: Path, ja_path: Path) -> List[Dict]:
        """HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¯”è¼ƒã—ã¦æœªç¿»è¨³éƒ¨åˆ†ã‚’æ¤œå‡º"""
        issues = []
        
        if not ja_path.exists():
            self.log(f"âš ï¸  æ—¥æœ¬èªç‰ˆãŒå­˜åœ¨ã—ã¾ã›ã‚“: {ja_path.relative_to(HTML_JA)}")
            return issues
        
        try:
            with open(en_path, 'r', encoding='utf-8') as f:
                en_soup = BeautifulSoup(f, 'html.parser')
            
            with open(ja_path, 'r', encoding='utf-8') as f:
                ja_soup = BeautifulSoup(f, 'html.parser')
        except Exception as e:
            self.log(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return issues
        
        # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ã¿ã‚’æ¯”è¼ƒ
        en_main = en_soup.find('div', {'role': 'main'}) or en_soup.find('main') or en_soup.body
        ja_main = ja_soup.find('div', {'role': 'main'}) or ja_soup.find('main') or ja_soup.body
        
        if not en_main or not ja_main:
            return issues
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        ja_texts = self.extract_text_from_element(ja_main)
        
        for text, context in ja_texts:
            if self.is_likely_english(text):
                issues.append({
                    'file': str(ja_path.relative_to(HTML_JA)),
                    'text': text,
                    'context': context,
                    'severity': 'high' if len(text.split()) > 3 else 'medium',
                })
        
        return issues
    
    def scan_directory(self):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        if not HTML_JA.exists():
            print(f"[ERROR] æ—¥æœ¬èªHTMLãƒ“ãƒ«ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {HTML_JA}")
            print("   å…ˆã« 'make html-ja' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return
        
        print(f"[INFO] ã‚¹ã‚­ãƒ£ãƒ³ä¸­: {HTML_JA}")
        print()
        
        html_files = list(HTML_JA.rglob("*.html"))
        
        for ja_path in html_files:
            # ãƒ“ãƒ«ãƒ‰ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—
            if any(x in str(ja_path) for x in ['genindex', 'search', '_static', '_sources']):
                continue
            
            self.stats['files_checked'] += 1
            
            # å¯¾å¿œã™ã‚‹è‹±èªãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
            rel_path = ja_path.relative_to(HTML_JA)
            en_path = HTML_EN / rel_path
            
            if not en_path.exists():
                continue
            
            file_issues = self.compare_html_files(en_path, ja_path)
            
            if file_issues:
                self.stats['files_with_issues'] += 1
                self.stats['issues_found'] += len(file_issues)
                self.issues.extend(file_issues)
                
                print(f"ğŸ“„ {rel_path}")
                for issue in file_issues:
                    severity_icon = "ğŸ”´" if issue['severity'] == 'high' else "ğŸŸ¡"
                    print(f"   {severity_icon} {issue['context']}: '{issue['text']}'")
                print()
    
    def generate_report(self, output_file: Path):
        """è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report = {
            'timestamp': str(Path.ctime(Path(__file__))),
            'stats': self.stats,
            'issues': self.issues,
            'issues_by_file': {},
        }
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ã«é›†è¨ˆ
        for issue in self.issues:
            file = issue['file']
            if file not in report['issues_by_file']:
                report['issues_by_file'][file] = []
            report['issues_by_file'][file].append({
                'text': issue['text'],
                'context': issue['context'],
                'severity': issue['severity'],
            })
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {output_file}")
    
    def print_summary(self):
        """ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        print("=" * 70)
        print("ğŸ“Š ã‚¹ã‚­ãƒ£ãƒ³çµæœã‚µãƒãƒªãƒ¼")
        print("=" * 70)
        print(f"ãƒã‚§ãƒƒã‚¯ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°: {self.stats['files_checked']}")
        print(f"å•é¡ŒãŒè¦‹ã¤ã‹ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«: {self.stats['files_with_issues']}")
        print(f"æœªç¿»è¨³ã®å¯èƒ½æ€§ãŒã‚ã‚‹ç®‡æ‰€: {self.stats['issues_found']}")
        print()
        
        if self.stats['issues_found'] > 0:
            # é »å‡ºã™ã‚‹æœªç¿»è¨³ãƒ†ã‚­ã‚¹ãƒˆ
            text_count = {}
            for issue in self.issues:
                text = issue['text']
                text_count[text] = text_count.get(text, 0) + 1
            
            print("ğŸ” é »å‡ºã™ã‚‹æœªç¿»è¨³ãƒ†ã‚­ã‚¹ãƒˆ (Top 10):")
            for text, count in sorted(text_count.items(), key=lambda x: x[1], reverse=True)[:10]:
                print(f"   {count}å›: '{text}'")
            print()


class TranslationFixer:
    """ç¿»è¨³ã®è‡ªå‹•ä¿®æ­£"""
    
    def __init__(self, detector: UntranslatedDetector):
        self.detector = detector
        self.fixes_applied = 0
    
    def find_po_file(self, html_file: str) -> Path:
        """HTMLãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾å¿œã™ã‚‹POãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™"""
        # HTMLãƒ‘ã‚¹ã‹ã‚‰RSTãƒ‘ã‚¹ã‚’æ¨æ¸¬
        html_path = Path(html_file)
        rel_path = html_path.with_suffix('.rst')
        
        # POãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
        po_path = LOCALES_DIR / rel_path.with_suffix('.po')
        
        if not po_path.exists():
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ãŒé•ã†å ´åˆã®ä»£æ›¿ãƒ‘ã‚¹
            parts = list(rel_path.parts)
            if len(parts) > 1:
                po_path = LOCALES_DIR / Path(*parts[:-1]) / (parts[-1].replace('.rst', '.po'))
        
        return po_path if po_path.exists() else None
    
    def suggest_translation(self, english_text: str) -> str:
        """ç°¡å˜ãªç¿»è¨³å€™è£œã‚’ææ¡ˆï¼ˆè¾æ›¸ãƒ™ãƒ¼ã‚¹ï¼‰"""
        # åŸºæœ¬çš„ãªç¿»è¨³è¾æ›¸
        translations = {
            'New Teams': 'æ–°è¦ãƒãƒ¼ãƒ ',
            'Returning Teams': 'æ—¢å­˜ãƒãƒ¼ãƒ ',
            'Programming Resources': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ãƒªã‚½ãƒ¼ã‚¹',
            'CAD Resources': 'CADãƒªã‚½ãƒ¼ã‚¹',
            'Competition Manual': 'ç«¶æŠ€ãƒãƒ‹ãƒ¥ã‚¢ãƒ«',
            'Team Management': 'ãƒãƒ¼ãƒ ç®¡ç†',
            'Frequently Asked Questions': 'ã‚ˆãã‚ã‚‹è³ªå•',
            'Downloads': 'ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰',
            'Next': 'æ¬¡ã¸',
            'Previous': 'å‰ã¸',
            'Home': 'ãƒ›ãƒ¼ãƒ ',
            'Search': 'æ¤œç´¢',
            'Table of Contents': 'ç›®æ¬¡',
            'Note': 'æ³¨è¨˜',
            'Warning': 'è­¦å‘Š',
            'Important': 'é‡è¦',
            'Tip': 'ãƒ’ãƒ³ãƒˆ',
            'See also': 'å‚ç…§',
        }
        
        return translations.get(english_text, f"[è¦ç¿»è¨³: {english_text}]")
    
    def fix_issues(self):
        """å•é¡Œã‚’è‡ªå‹•ä¿®æ­£"""
        print("ğŸ”§ è‡ªå‹•ä¿®æ­£ã‚’å®Ÿè¡Œä¸­...")
        print()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ã«å•é¡Œã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        issues_by_file = {}
        for issue in self.detector.issues:
            file = issue['file']
            if file not in issues_by_file:
                issues_by_file[file] = []
            issues_by_file[file].append(issue)
        
        for file, issues in issues_by_file.items():
            print(f"ğŸ“ ä¿®æ­£ä¸­: {file}")
            
            po_file = self.find_po_file(file)
            if not po_file:
                print(f"   âš ï¸  å¯¾å¿œã™ã‚‹POãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                continue
            
            print(f"   ğŸ“„ POãƒ•ã‚¡ã‚¤ãƒ«: {po_file.relative_to(PROJECT_ROOT)}")
            
            for issue in issues:
                suggestion = self.suggest_translation(issue['text'])
                print(f"   ğŸ’¡ '{issue['text']}' â†’ '{suggestion}'")
                # å®Ÿéš›ã®ä¿®æ­£ã¯POãƒ•ã‚¡ã‚¤ãƒ«ç·¨é›†ãŒå¿…è¦
            
            print()


def main():
    parser = argparse.ArgumentParser(
        description='HTMLãƒ“ãƒ«ãƒ‰ã®è‹±èªæ®‹å­˜éƒ¨åˆ†ã‚’æ¤œå‡ºãƒ»ä¿®æ­£',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # æ¤œå‡ºã®ã¿ï¼ˆè©³ç´°è¡¨ç¤ºï¼‰
  python detect_untranslated.py --check -v
  
  # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
  python detect_untranslated.py --report -o report.json
  
  # è‡ªå‹•ä¿®æ­£ï¼ˆè¦ç¢ºèªï¼‰
  python detect_untranslated.py --fix
        """
    )
    
    parser.add_argument('--check', action='store_true',
                        help='æœªç¿»è¨³éƒ¨åˆ†ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰')
    parser.add_argument('--fix', action='store_true',
                        help='è‡ªå‹•ä¿®æ­£ã‚’è©¦ã¿ã‚‹')
    parser.add_argument('--report', action='store_true',
                        help='è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ')
    parser.add_argument('-o', '--output', default='untranslated_report.json',
                        help='ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: untranslated_report.jsonï¼‰')
    parser.add_argument('-v', '--verbose', action='store_true',
                        help='è©³ç´°ãƒ­ã‚°ã‚’è¡¨ç¤º')
    
    args = parser.parse_args()
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ --check
    if not (args.check or args.fix or args.report):
        args.check = True
    
    detector = UntranslatedDetector(verbose=args.verbose)
    detector.scan_directory()
    detector.print_summary()
    
    if args.report:
        output_path = Path(args.output)
        detector.generate_report(output_path)
    
    if args.fix:
        fixer = TranslationFixer(detector)
        fixer.fix_issues()
        print(f"âœ… ä¿®æ­£å€™è£œã‚’æç¤ºã—ã¾ã—ãŸã€‚å®Ÿéš›ã®ä¿®æ­£ã«ã¯POãƒ•ã‚¡ã‚¤ãƒ«ã®ç·¨é›†ãŒå¿…è¦ã§ã™ã€‚")
    
    # çµ‚äº†ã‚³ãƒ¼ãƒ‰
    sys.exit(1 if detector.stats['issues_found'] > 0 else 0)


if __name__ == '__main__':
    main()
